{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Load chunked context data embedding vectors into an indexed database.  We will use open source Milvus.\n",
    "\n",
    "Demo in progress..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first download the Milvus documentation to a local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pymilvus.readthedocs.io/en/latest\n",
      "/Users/christybergman/Documents/christy_coding_scratch/data/milvus_documentation\n"
     ]
    }
   ],
   "source": [
    "DOCS_PAGE=\"https://pymilvus.readthedocs.io/en/latest\"\n",
    "LOCAL_DIR=\"~/Documents/christy_coding_scratch/data/milvus_documentation\"\n",
    "!echo $DOCS_PAGE\n",
    "!echo $LOCAL_DIR\n",
    "\n",
    "# !wget -r -A.html $DOCS_PAGE -P $LOCAL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries.\n",
    "import time, os\n",
    "import numpy as np\n",
    "\n",
    "# Import langchain.\n",
    "#!pip install langchain html2text unstructured\n",
    "# import html2text, unstructured\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1 documents\n",
      "type: <class 'list'>, len: 1, type: <class 'langchain.schema.document.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# loader = ReadTheDocsLoader(DOCS_PAGE)\n",
    "loader = UnstructuredURLLoader(urls=[DOCS_PAGE])\n",
    "data = loader.load()\n",
    "\n",
    "print(f\"loaded {len(data)} documents\")\n",
    "print(f\"type: {type(data)}, len: {len(data)}, type: {type(data[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to vectorstore.\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk and embed data\n",
    "\n",
    "**First, choose an embedding model** <br>\n",
    "Most tutorials default to the OpenAI embedding model, which costs money.  You don't have to do that.\n",
    "\n",
    "In the code below, we will use an open source SentenceTransformer embedding model, hosted on HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "  (2): Normalize()\n",
      ")\n",
      "embedding vector length: 384, chunk_overlap: 58.0\n"
     ]
    }
   ],
   "source": [
    "# Import torch.\n",
    "import torch\n",
    "\n",
    "# Initialize torch settings\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 415\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "model_name = \"all-MiniLM-L12-v2\"\n",
    "retriever = SentenceTransformer(model_name, device=DEVICE)\n",
    "print(type(retriever))\n",
    "print(retriever)\n",
    "\n",
    "# Save params for later.\n",
    "# TOKENIZER_CONTEXT_WINDOW = retriever.get_max_seq_length()\n",
    "CHUNK_SIZE = retriever.get_sentence_embedding_dimension()\n",
    "chunk_overlap = np.round(CHUNK_SIZE * 0.15, 0)\n",
    "print(f\"embedding vector length: {CHUNK_SIZE}, chunk_overlap: {chunk_overlap}\")\n",
    "# 384, 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'list'>, len: 1, type: <class 'langchain.schema.document.Document'>\n",
      "chunking time: 0.003075122833251953\n"
     ]
    }
   ],
   "source": [
    "# Chunk the data using Langchain's HTML splitter\n",
    "start_time = time.time()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len)\n",
    "documents = text_splitter.split_documents(data)\n",
    "print(f\"type: {type(documents)}, len: {len(data)}, type: {type(data[0])}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"chunking time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into HuggingFace using your [API token](https://huggingface.co/settings/tokens). \n",
    "\n",
    "ðŸ’¡ Best practice:  Read tokens from your environment. <br>\n",
    "> Some people choose to create an input field, for user to type their token. <br>\n",
    "> Either way, never hard-code your token into public code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/christybergman/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to huggingface_hub\n",
    "hub_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "login(token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed chunks in batches of 100 chunks at a time.\n",
    "# TODO - move all this to a utility function.\n",
    "\n",
    "# Batch of data from pandas DataFrame.\n",
    "batch = df.head(100).copy()\n",
    "\n",
    "# 1. Change primary key type to string.\n",
    "batch[\"movie_index\"] = batch[\"movie_index\"].apply(lambda x: str(x))\n",
    "\n",
    "# 2. Truncate reviews to 512 characters.\n",
    "batch[\"text\"] = batch[\"text\"].apply(lambda x: x[:512])\n",
    "\n",
    "# 3. Add embeddings as new column in df.\n",
    "review_embeddings = retriever.encode(batch['text']).tolist()\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(review_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# 4. Convert the embeddings to np.float32\n",
    "converted_values = list(map(np.float32, review_embeddings))\n",
    "batch['embeddings'] = converted_values\n",
    "\n",
    "# 5. Reorder columns so pk first, labels at end.\n",
    "new_order = [\"movie_index\", \"text\", \"embeddings\", \"label_int\", \"label\"]\n",
    "batch = batch[new_order]\n",
    "\n",
    "display(batch.head(2))\n",
    "assert len(batch.text[0]) == 512\n",
    "assert len(batch.embeddings[0]) == TOKENIZER_EMBEDDING_LENGTH\n",
    "print(batch.dtypes)\n",
    "print(f\"type embeddings: {type(batch.embeddings[0])}, {type(batch.embeddings[0][0])}\")\n",
    "\n",
    "# milvus field random, only supports list\n",
    "# milvus field embeddings, supports numpy.ndarray and list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
